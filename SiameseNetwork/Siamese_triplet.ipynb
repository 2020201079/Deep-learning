{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61UNTTrN970K",
    "outputId": "fdf81999-a543-45ef-aee4-6582352d0039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zeBrh7hkMUhZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import  Activation, Dense, Reshape\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.optimizers import RMSprop, Adam,SGD\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1VOWtzbMeT6",
    "outputId": "f204c5e0-038c-4a4c-9e0a-1c5608b7c8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHDh0kCjMiF9"
   },
   "source": [
    "## For each digit making 3000 anchor , positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "osdFCJeGMnEj"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "anchor_data_set = []\n",
    "positive_data_set = []\n",
    "negative_data_set = []\n",
    "#new_label = []\n",
    "for i in range(0,10):\n",
    "  x_train_same = train_X[train_y == i]\n",
    "  x_train_diff = train_X[train_y != i]\n",
    "  #select 800 positive samples for each number\n",
    "  for k in range(3000):\n",
    "    ind_anchor = random.randint(0,len(x_train_same)-1)\n",
    "    ind_pos = random.randint(0,len(x_train_same)-1)\n",
    "    ind_neg = random.randint(0,len(x_train_diff)-1)\n",
    "    anchor_data_set.append(x_train_same[ind_anchor])\n",
    "    positive_data_set.append(x_train_same[ind_pos])                   \n",
    "    negative_data_set.append(x_train_diff[ind_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xRE-OJwKNs89"
   },
   "outputs": [],
   "source": [
    "positive_data_set = np.stack(positive_data_set,axis=0).astype('float64')\n",
    "negative_data_set = np.stack(negative_data_set,axis=0).astype('float64')\n",
    "anchor_data_set = np.stack(anchor_data_set,axis=0).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PEoDj2mLOBBL"
   },
   "outputs": [],
   "source": [
    "positive_data_set = positive_data_set.reshape(-1,28*28)\n",
    "negative_data_set = negative_data_set.reshape(-1,28*28)\n",
    "anchor_data_set = anchor_data_set.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxF7eNo8ONOS",
    "outputId": "0435571c-af86-4969-97bc-00ae5770fa58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784)\n",
      "(30000, 784)\n",
      "(30000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(positive_data_set.shape)\n",
    "print(negative_data_set.shape)\n",
    "print(anchor_data_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6FNDrHc-OVNn"
   },
   "outputs": [],
   "source": [
    "def buildBranchModel():\n",
    "  inpx = Input(shape=(784,))\n",
    "  x = Dense(128,activation='relu')(inpx)\n",
    "  x = Dropout(0.1)(x)\n",
    "  x = Dense(128,activation='relu')(x)\n",
    "  x = Dropout(0.1)(x)\n",
    "  x = Dense(128,activation='relu')(x)\n",
    "  return Model([inpx],[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6N4SEhmpOeBo"
   },
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        anchor, positive, negative = inputs\n",
    "        p_dist = K.sum(K.square(anchor-positive), axis=1)\n",
    "        n_dist = K.sum(K.square(anchor-negative), axis=1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K8Y5bqWrQ1w4"
   },
   "outputs": [],
   "source": [
    "def dummy_loss(y_true, y_pred):\n",
    "    #print y_true.type,y_pred.type\n",
    "    #return K.zeros_like(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ULyz9bVByfBg"
   },
   "outputs": [],
   "source": [
    "test_images = test_X.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTu7FCUJqC7i"
   },
   "source": [
    "# RMS Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JvtsNJmVOtqM"
   },
   "outputs": [],
   "source": [
    "branchModel = buildBranchModel()\n",
    "input_anchor = Input(shape=(784,))\n",
    "input_positive = Input(shape=(784,))\n",
    "input_negative = Input(shape=(784,))\n",
    "\n",
    "output_anchor = branchModel(input_anchor)\n",
    "output_positive = branchModel(input_positive)\n",
    "output_negative = branchModel(input_negative)\n",
    "\n",
    "loss_layer = TripletLossLayer(alpha=500)([output_anchor,output_positive,output_negative])\n",
    "\n",
    "model = Model([input_anchor,input_positive,input_negative],loss_layer)\n",
    "\n",
    "rms = RMSprop(lr=0.0001)\n",
    "\n",
    "model.compile(loss=dummy_loss,optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loByyj54RzI-",
    "outputId": "4a20627b-b9e5-4c37-a47a-c34d61158af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  5/750 [..............................] - ETA: 20s - loss: 702333.4250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 21s 27ms/step - loss: 224192.9813\n",
      "Epoch 2/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 17177.5763\n",
      "Epoch 3/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 9247.7044\n",
      "Epoch 4/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 6701.6894\n",
      "Epoch 5/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 5483.8489\n",
      "Epoch 6/25\n",
      "750/750 [==============================] - 21s 27ms/step - loss: 4596.9961\n",
      "Epoch 7/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 4032.5974\n",
      "Epoch 8/25\n",
      "750/750 [==============================] - 21s 27ms/step - loss: 3480.9879\n",
      "Epoch 9/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 3219.7704\n",
      "Epoch 10/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 2805.9958\n",
      "Epoch 11/25\n",
      "750/750 [==============================] - 20s 27ms/step - loss: 2513.1063\n",
      "Epoch 12/25\n",
      "750/750 [==============================] - 21s 27ms/step - loss: 2155.0866\n",
      "Epoch 13/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 2081.0292\n",
      "Epoch 14/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1834.2387\n",
      "Epoch 15/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1777.6456\n",
      "Epoch 16/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1585.9290\n",
      "Epoch 17/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1558.7635\n",
      "Epoch 18/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1449.6119\n",
      "Epoch 19/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1328.6248\n",
      "Epoch 20/25\n",
      "750/750 [==============================] - 21s 27ms/step - loss: 1225.8610\n",
      "Epoch 21/25\n",
      "750/750 [==============================] - 21s 27ms/step - loss: 1164.8515\n",
      "Epoch 22/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1174.0838\n",
      "Epoch 23/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 1160.6392\n",
      "Epoch 24/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 966.8166\n",
      "Epoch 25/25\n",
      "750/750 [==============================] - 21s 28ms/step - loss: 969.6541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a84153d10>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([anchor_data_set,positive_data_set,negative_data_set],None,epochs=25,batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "os-iX5SoXLRZ"
   },
   "outputs": [],
   "source": [
    "# create an image pool and save the output of the model here\n",
    "image_pool = []\n",
    "for i in range(0,10):\n",
    "  image_pool.append(train_X[train_y == i][0])\n",
    "image_pool = np.stack(image_pool,axis=0).astype('float64').reshape(-1,28*28)\n",
    "image_pool_output = []\n",
    "for img in image_pool:\n",
    "  image_pool_output.append(branchModel(img.reshape(1,784)))\n",
    "image_pool_output = np.stack(image_pool_output,axis=0).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QZr7cIA1nZJ2"
   },
   "outputs": [],
   "source": [
    "def predict(test_image):\n",
    "  pred_1 = branchModel(test_image.reshape(1,784))\n",
    "  dis = K.mean((image_pool_output-pred_1)**2,axis=2).numpy()\n",
    "  return np.argmin(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Gk5s7fCkng10"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for img in test_images:\n",
    "  predictions.append(predict(img))\n",
    "correct_predictions_rms = (predictions == test_y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4AC9tFUnxJL",
    "outputId": "eea543e4-53e5-4c2e-e9f1-647207156c91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9177  out of  10000 accuracy is :  0.9177\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions_rms,\" out of \",test_images.shape[0],\"accuracy is : \",correct_predictions_rms/test_images.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE9rEZnnqGSP"
   },
   "source": [
    "# Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bDiGzHAYqFm9"
   },
   "outputs": [],
   "source": [
    "branchModel_adam = buildBranchModel()\n",
    "input_anchor_adam = Input(shape=(784,))\n",
    "input_positive_adam = Input(shape=(784,))\n",
    "input_negative_adam = Input(shape=(784,))\n",
    "\n",
    "output_anchor_adam = branchModel_adam(input_anchor_adam)\n",
    "output_positive_adam = branchModel_adam(input_positive_adam)\n",
    "output_negative_adam = branchModel_adam(input_negative_adam)\n",
    "\n",
    "loss_layer_adam = TripletLossLayer(alpha=500)([output_anchor_adam,output_positive_adam,output_negative_adam])\n",
    "\n",
    "model_adam = Model([input_anchor_adam,input_positive_adam,input_negative_adam],loss_layer_adam)\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "\n",
    "model_adam.compile(loss=dummy_loss,optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHUZsqF4qxXx",
    "outputId": "6f8624aa-20cf-4b73-89d8-df1277a1e9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  4/750 [..............................] - ETA: 15s - loss: 916896.1875 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 16s 22ms/step - loss: 275849.1340\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 35851.5631\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 18915.1793\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 12986.4755\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 9883.0245\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 8330.8902\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 6795.8056\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 5795.6980\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 5049.2246\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 4227.2036\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 3651.4640\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 3127.0217\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 2819.3169\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 2427.6975\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 2122.0776\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 1873.1723\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 1677.9598\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 1558.2925\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 1445.7437\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 1313.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a6b1c0990>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adam.fit([anchor_data_set,positive_data_set,negative_data_set],None,epochs=20,batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rq3gKg2Oq7B2",
    "outputId": "e8647e5b-b538-4ae4-fc1f-19799aa5be74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9016  out of  10000 accuracy is :  0.9016\n"
     ]
    }
   ],
   "source": [
    "# create an image pool and save the output of the model here\n",
    "image_pool_adam = []\n",
    "for i in range(0,10):\n",
    "  image_pool_adam.append(train_X[train_y == i][0])\n",
    "image_pool_adam = np.stack(image_pool_adam,axis=0).astype('float64').reshape(-1,28*28)\n",
    "image_pool_output_adam = []\n",
    "for img in image_pool_adam:\n",
    "  image_pool_output_adam.append(branchModel_adam(img.reshape(1,784)))\n",
    "image_pool_output_adam = np.stack(image_pool_output_adam,axis=0).astype('float64')\n",
    "\n",
    "def predict_adam(test_image):\n",
    "  pred_1 = branchModel_adam(test_image.reshape(1,784))\n",
    "  dis = K.mean((image_pool_output_adam-pred_1)**2,axis=2).numpy()\n",
    "  return np.argmin(dis)\n",
    "\n",
    "predictions_adam = []\n",
    "for img in test_images:\n",
    "  predictions_adam.append(predict_adam(img))\n",
    "correct_predictions_adam = (predictions_adam == test_y).sum()\n",
    "\n",
    "print(correct_predictions_adam,\" out of \",test_images.shape[0],\"accuracy is : \",correct_predictions_adam/test_images.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dswTSbnrlNn"
   },
   "source": [
    "# SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JX1Uy05DrrEQ"
   },
   "outputs": [],
   "source": [
    "branchModel_sgd = buildBranchModel()\n",
    "input_anchor_sgd = Input(shape=(784,))\n",
    "input_positive_sgd = Input(shape=(784,))\n",
    "input_negative_sgd = Input(shape=(784,))\n",
    "\n",
    "output_anchor_sgd = branchModel_sgd(input_anchor_sgd)\n",
    "output_positive_sgd = branchModel_sgd(input_positive_sgd)\n",
    "output_negative_sgd = branchModel_sgd(input_negative_sgd)\n",
    "\n",
    "loss_layer_sgd = TripletLossLayer(alpha=500)([output_anchor_sgd,output_positive_sgd,output_negative_sgd])\n",
    "\n",
    "model_sgd = Model([input_anchor_sgd,input_positive_sgd,input_negative_sgd],loss_layer_sgd)\n",
    "\n",
    "sgd = SGD(lr=0.0000001, momentum=0.2)\n",
    "\n",
    "model_sgd.compile(loss=dummy_loss,optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTYYnJajr-q4",
    "outputId": "d36bb547-0a46-4c7a-8fd5-33639c29bb74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  7/750 [..............................] - ETA: 14s - loss: 1067518.8661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 15s 21ms/step - loss: 67373.3579\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 8836.9947\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 7197.0206\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 6110.5845\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 5378.5418\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 4967.0193\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 4580.2856\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 4371.4013\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 3926.1456\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 3609.5093\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 3632.4019\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 3444.1429\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 3238.8351\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 3025.9857\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 2791.1832\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 2753.5576\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 2633.6546\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 2508.2717\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 2451.1518\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 15s 21ms/step - loss: 2455.8983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a65e82d90>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd.fit([anchor_data_set,positive_data_set,negative_data_set],None,epochs=20,batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HcFu-KtsD27",
    "outputId": "915e316f-8bc5-475e-d9ea-126087ed4df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9177  out of  10000 accuracy is :  0.9177\n"
     ]
    }
   ],
   "source": [
    "# create an image pool and save the output of the model here\n",
    "image_pool_sgd = []\n",
    "for i in range(0,10):\n",
    "  image_pool_sgd.append(train_X[train_y == i][0])\n",
    "image_pool_sgd = np.stack(image_pool_sgd,axis=0).astype('float64').reshape(-1,28*28)\n",
    "image_pool_output_sgd = []\n",
    "for img in image_pool_sgd:\n",
    "  image_pool_output_sgd.append(branchModel_sgd(img.reshape(1,784)))\n",
    "image_pool_output_sgd = np.stack(image_pool_output_sgd,axis=0).astype('float64')\n",
    "\n",
    "def predict_sgd(test_image):\n",
    "  pred_1 = branchModel_sgd(test_image.reshape(1,784))\n",
    "  dis = K.mean((image_pool_output_sgd-pred_1)**2,axis=2).numpy()\n",
    "  return np.argmin(dis)\n",
    "\n",
    "predictions_sgd = []\n",
    "for img in test_images:\n",
    "  predictions_sgd.append(predict(img))\n",
    "correct_predictions_sgd = (predictions_sgd == test_y).sum()\n",
    "\n",
    "print(correct_predictions_sgd,\" out of \",test_images.shape[0],\"accuracy is : \",correct_predictions_sgd/test_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EoAF8RqjCkXa",
    "outputId": "b9773db6-5ad3-4f55-ee77-b26a449f06f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+--------+\n",
      "|          | Adam   | RMSProp  |  SGD   |\n",
      "+----------+--------+----------+--------+\n",
      "| Accuracy | 0.9016 |  0.9177  | 0.9177 |\n",
      "+----------+--------+----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['','Adam ', 'RMSProp ','SGD'])\n",
    "t.add_row(['Accuracy',correct_predictions_adam/test_images.shape[0],correct_predictions_rms/test_images.shape[0],correct_predictions_sgd/test_images.shape[0]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLC_Q40pFEfA"
   },
   "source": [
    "# Hyper parameter - margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "8Ca9L1ymFDdq"
   },
   "outputs": [],
   "source": [
    "branchModel_200 = buildBranchModel()\n",
    "input_anchor_200 = Input(shape=(784,))\n",
    "input_positive_200 = Input(shape=(784,))\n",
    "input_negative_200 = Input(shape=(784,))\n",
    "\n",
    "output_anchor_200 = branchModel_adam(input_anchor_200)\n",
    "output_positive_200 = branchModel_adam(input_positive_200)\n",
    "output_negative_200 = branchModel_adam(input_negative_200)\n",
    "\n",
    "loss_layer_200 = TripletLossLayer(alpha=200)([output_anchor_200,output_positive_200,output_negative_200])\n",
    "\n",
    "model_200 = Model([input_anchor_200,input_positive_200,input_negative_200],loss_layer_200)\n",
    "\n",
    "adam = Adam(lr=0.00001)\n",
    "\n",
    "model_200.compile(loss=dummy_loss,optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ha5FzZ6Fpo5",
    "outputId": "b6d8d653-cb04-4573-bb41-61f68ff6d1b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  7/750 [..............................] - ETA: 15s - loss: 812.0749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 17s 22ms/step - loss: 608.9409\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 470.1982\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 431.1674\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 433.5532\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 349.0256\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 429.6138\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 361.0731\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 380.5100\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 359.8615\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 383.3161\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 339.9912\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 352.2130\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 304.1325\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 370.6249\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 336.5750\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 308.1399\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 294.0963\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 313.6363\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 324.7526\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 309.1570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a63ee3090>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_200.fit([anchor_data_set,positive_data_set,negative_data_set],None,epochs=20,batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IB0A_UGtF7gk",
    "outputId": "930d6df1-cf70-4e19-dca5-c89c40e35077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3341  out of  10000 accuracy is :  0.3341\n"
     ]
    }
   ],
   "source": [
    "# create an image pool and save the output of the model here\n",
    "image_pool_200 = []\n",
    "for i in range(0,10):\n",
    "  image_pool_200.append(train_X[train_y == i][0])\n",
    "image_pool_200 = np.stack(image_pool_200,axis=0).astype('float64').reshape(-1,28*28)\n",
    "image_pool_output_200 = []\n",
    "for img in image_pool_200:\n",
    "  image_pool_output_200.append(branchModel_200(img.reshape(1,784)))\n",
    "image_pool_output_200 = np.stack(image_pool_output_200,axis=0).astype('float64')\n",
    "\n",
    "def predict_200(test_image):\n",
    "  pred_1 = branchModel_200(test_image.reshape(1,784))\n",
    "  dis = K.mean((image_pool_output_200-pred_1)**2,axis=2).numpy()\n",
    "  return np.argmin(dis)\n",
    "\n",
    "predictions_200 = []\n",
    "for img in test_images:\n",
    "  predictions_200.append(predict_200(img))\n",
    "correct_predictions_200 = (predictions_200 == test_y).sum()\n",
    "\n",
    "print(correct_predictions_200,\" out of \",test_images.shape[0],\"accuracy is : \",correct_predictions_200/test_images.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLBsVybCHklv"
   },
   "source": [
    "## As we can see accuracy dropped from 91% to 33% on changing margin from 500 to 200"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Siamese_triplet_loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
